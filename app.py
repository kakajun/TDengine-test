import streamlit as st
import pandas as pd
import taosws
from openai import OpenAI
import json
import re

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="å…‰ä¼æ•°æ® AI åŠ©æ‰‹",
    page_icon="â˜€ï¸",
    layout="wide"
)

# --- åˆå§‹åŒ– Session State ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- Sidebar: é…ç½® ---
with st.sidebar:
    st.header("ğŸ”§ è®¾ç½®")

    st.subheader("1. æ•°æ®åº“é…ç½®")
    td_host = st.text_input("TDengine Host", "localhost")
    td_port = st.text_input("TDengine Port", "6041")
    td_user = st.text_input("Username", "root")
    td_pass = st.text_input("Password", "taosdata", type="password")

    st.subheader("2. AI æ¨¡å‹é…ç½®")
    api_key = st.text_input("API Key", type="password",
                            help="è¯·è¾“å…¥æ‚¨çš„ OpenAI/DeepSeek ç­‰æ¨¡å‹çš„ API Key")
    base_url = st.text_input("Base URL", "https://api.deepseek.com",
                             help="ä¾‹å¦‚ DeepSeek ä½¿ç”¨: https://api.deepseek.com")
    model_name = st.text_input(
        "Model Name", "deepseek-chat", help="DeepSeek å¡«: deepseek-chat; OpenAI å¡«: gpt-4o")

    if st.button("ğŸ”Œ æµ‹è¯• API è¿æ¥"):
        if not api_key:
            st.error("è¯·å…ˆè¾“å…¥ API Key")
        else:
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                # å°è¯•ä¸€ä¸ªæç®€çš„è¯·æ±‚
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": "Hi"}],
                    max_tokens=5
                )
                st.success(f"âœ… è¿æ¥æˆåŠŸï¼å½“å‰æ¨¡å‹ '{model_name}' å¯ç”¨ã€‚")
            except Exception as e:
                st.error(
                    f"âŒ è¿æ¥å¤±è´¥\n\n**é”™è¯¯ä¿¡æ¯:** {str(e)}\n\n**æ’æŸ¥å»ºè®®:**\n1. æ£€æŸ¥ Model Name æ˜¯å¦æ­£ç¡® (å½“å‰: `{model_name}`)\n2. æ£€æŸ¥ Base URL æ˜¯å¦æ­£ç¡® (å½“å‰: `{base_url}`)\n3. ç¡®è®¤ API Key æ˜¯å¦æœ‰æ•ˆ")

    if st.button("æ¸…é™¤èŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.rerun()

# --- æ ¸å¿ƒå‡½æ•° ---


def get_db_connection():
    dsn = f"taosws://{td_user}:{td_pass}@{td_host}:{td_port}"
    return taosws.connect(dsn)


def execute_query(sql):
    try:
        conn = get_db_connection()
        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“
        cursor = conn.cursor()
        cursor.execute("USE solar_power")

        cursor.execute(sql)
        fields = [field[0] for field in cursor.description]
        data = cursor.fetchall()

        cursor.close()
        conn.close()

        return pd.DataFrame(data, columns=fields), None
    except Exception as e:
        return None, str(e)


def get_sql_from_llm(user_query):
    if not api_key:
        return None, "è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è®¾ç½® API Key"

    client = OpenAI(api_key=api_key, base_url=base_url)

    # å®šä¹‰ Schema å’Œ Prompt
    schema_info = """
    Database: solar_power
    Super Table: meters
    Columns:
      - ts (TIMESTAMP): æ—¶é—´æˆ³
      - current (FLOAT): ç”µæµ (A)
      - voltage (FLOAT): ç”µå‹ (V)
      - power (FLOAT): åŠŸç‡ (kW)
      - energy_daily (FLOAT): å½“æ—¥ç´¯è®¡å‘ç”µé‡ (kWh)
    Tags:
      - location (BINARY): åœºç«™åç§° (ä¾‹å¦‚ 'Station_A', 'Station_B')
      - model (BINARY): è®¾å¤‡å‹å·
    """

    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ª TDengine SQL ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸º TDengine SQL è¯­å¥ã€‚

    ã€æ•°æ®åº“ç»“æ„ã€‘
    {schema_info}

    ã€TDengine ç‰¹æœ‰è¯­æ³•è§„åˆ™ã€‘
    1. **æ ¸å¿ƒè§„åˆ™ (INTERVAL)**ï¼šå½“ä½¿ç”¨ `INTERVAL` è¿›è¡Œæ—¶é—´çª—å£èšåˆï¼ˆé™é‡‡æ ·ï¼‰æ—¶ï¼ŒSELECT åˆ—è¡¨ä¸­**ç»å¯¹ä¸èƒ½**åŒ…å« `ts` åˆ—ï¼Œå¿…é¡»ä½¿ç”¨ `_wstart`ã€‚
    2. **ç»˜å›¾è¦æ±‚**ï¼šä¸ºäº†è®©å‰ç«¯èƒ½ç”»å›¾ï¼Œè¯·åŠ¡å¿…å°† `_wstart` é‡å‘½åä¸º `ts`ã€‚
       - âœ… æ­£ç¡®: `SELECT _wstart AS ts, avg(power) FROM meters ... INTERVAL(1h)`
       - âŒ é”™è¯¯: `SELECT ts, avg(power) ... INTERVAL(1h)`
    3. **æ™®é€šèšåˆ**ï¼šå¦‚æœæ²¡æœ‰ `INTERVAL`ï¼ŒSELECT åˆ—è¡¨ä¸­**ç»å¯¹ä¸èƒ½**åŒ…å« `ts` æˆ– `_wstart`ã€‚
       - âœ… æ­£ç¡®: `SELECT avg(power) FROM meters ...`
       - âŒ é”™è¯¯: `SELECT ts, avg(power) ...`
    4. è·å–æœ€æ–°æ•°æ®ä½¿ç”¨ `ORDER BY ts DESC LIMIT 1` æˆ– `LAST_ROW()`ã€‚
    5. ä»Šå¤©çš„èŒƒå›´æ˜¯ `ts >= TODAY`ï¼Œè¿‡å»24å°æ—¶æ˜¯ `ts >= NOW - 24h`ã€‚
    6. å­—ç¬¦ä¸²å€¼éœ€è¦ç”¨å•å¼•å·åŒ…è£¹ã€‚

    ã€è¾“å‡ºè¦æ±‚ã€‘
    1. ä»…è¾“å‡º SQL è¯­å¥ï¼Œä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```sql ... ```ï¼‰ã€‚
    2. ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
    """

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            temperature=0
        )
        sql = response.choices[0].message.content.strip()
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ markdown æ ‡è®°
        sql = re.sub(r'^```sql\s*', '', sql)
        sql = re.sub(r'^```\s*', '', sql)
        sql = re.sub(r'\s*```$', '', sql)
        return sql, None
    except Exception as e:
        error_msg = f"AI è°ƒç”¨å¤±è´¥: {str(e)}\n\n(å½“å‰é…ç½® -> Model: {model_name}, Base URL: {base_url})"
        return None, error_msg

# --- ä¸»ç•Œé¢ ---


st.title("â˜€ï¸ å…‰ä¼åœºç«™æ•°æ®æ™ºèƒ½åŠ©æ‰‹")
st.markdown("ç›´æ¥è¾“å…¥é—®é¢˜ï¼Œä¾‹å¦‚ï¼š*â€œStation_A ä»Šå¤©çš„åŠŸç‡æ›²çº¿æ˜¯ä»€ä¹ˆï¼Ÿâ€* æˆ– *â€œStation_B æ˜¨å¤©çš„æ€»å‘ç”µé‡â€*")

# å±•ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "sql" in msg:
            st.code(msg["sql"], language="sql")
        if "data" in msg:
            df = msg["data"]
            st.dataframe(df)
            # è‡ªåŠ¨ç»˜å›¾é€»è¾‘
            if "ts" in df.columns and len(df) > 1:
                # å¯»æ‰¾æ•°å€¼åˆ—
                numeric_cols = df.select_dtypes(
                    include=['float', 'int']).columns
                if len(numeric_cols) > 0:
                    st.line_chart(df.set_index("ts")[numeric_cols])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. ç”Ÿæˆ SQL
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ğŸ¤” æ­£åœ¨æ€è€ƒ SQL...")

        sql, error = get_sql_from_llm(prompt)

        if error:
            message_placeholder.error(error)
            st.session_state.messages.append(
                {"role": "assistant", "content": f"âŒ é”™è¯¯: {error}"})
        else:
            message_placeholder.markdown(f"**ç”Ÿæˆçš„ SQL:**\n```sql\n{sql}\n```")

            # 3. æ‰§è¡ŒæŸ¥è¯¢
            with st.spinner("æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“..."):
                df, db_error = execute_query(sql)

            if db_error:
                st.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {db_error}")
                st.session_state.messages.append(
                    {"role": "assistant", "content": f"æ•°æ®åº“é”™è¯¯: {db_error}", "sql": sql})
            else:
                # 4. å±•ç¤ºç»“æœ
                st.success(f"æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•ã€‚")
                st.dataframe(df)

                # å°è¯•ç»˜å›¾
                if "ts" in df.columns and len(df) > 1:
                    numeric_cols = df.select_dtypes(
                        include=['float', 'int']).columns
                    if len(numeric_cols) > 0:
                        st.line_chart(df.set_index("ts")[numeric_cols])

                # ä¿å­˜åˆ°å†å²è®°å½• (è¿™é‡Œç®€åŒ–ï¼Œä¸ä¿å­˜ heavy dataframe åˆ° session state ä»¥å…å¡é¡¿ï¼Œåªä¿å­˜ SQL)
                # å®é™…ç”Ÿäº§ä¸­å¯ä»¥ä¼˜åŒ–
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "æŸ¥è¯¢å®Œæˆã€‚",
                    "sql": sql,
                    # "data": df # å¦‚æœéœ€è¦å†å²è®°å½•é‡Œä¹Ÿèƒ½é‡ç»˜å›¾è¡¨ï¼Œéœ€è¦ä¿å­˜ data
                })
